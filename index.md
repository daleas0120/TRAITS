---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: page
---
<center>
<center><img src="/TRAITS/assets/traits_logo.png" width="300" class="center"/> </center>
</center>

**LOOKING FOR COLLABORATORS! We would love to include the trustworthiness of your model in our forthcoming index.  Please get in touch either via <a href="mailto:trustworthy.ai.toolkit@gmail.com">email</a> or [through this nifty Google Form](https://docs.google.com/forms/d/e/1FAIpQLScH5_oJkwBK3pt8WjwjnXhkeBhITSmryM4RXiwnlve-Beg-Ug/viewform?usp=sf_link).**

The **Trustworthy AI Toolkit for Science (TRAITS)** is a model agnostic and task agnostic Python package inspired by various Trustworthy AI Frameworks. Common methods for evaluating the trustworthiness of a model may fail to provide insight into the source of the untrustworthiness. TRAITS allows users to answer questions about their model such as

- Is the model, data, and methodology transparent so that it is possible for a third party to reproduce results? 
- Is the model robust to noise in the data, so that if the data quality is degraded, model performance is unchanged?
- How badly is the model overparameterized? Can parameters be removed without changing model performance?
- Given that simpler models are inherently more interpretable than more complex models, how complex is the model?
- Given out-of-distribution data, how well does the model generalize?
- How robust against perturbation is the feature representation learned by the model?



